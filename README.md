# Metal Accelerated Tensor Library with Compute Graphs

A high-performance tensor library that leverages Metal for GPU acceleration, implements dynamic compute graphs for automatic differentiation (autograd), and provides Python bindings for ease of use in machine learning and scientific computing. 

**Note**: This project is primarily designed for learning and educational purposes. While it is capable of performing basic tensor operations and gradient computation, it is **not intended for production-level model building**. However, with further development, it could be used for simple model building tasks.

## Features

- **GPU Acceleration**: Utilizes Metal for efficient tensor computation on macOS devices.
- **Dynamic Compute Graphs**: Implements dynamic computation graphs for automatic differentiation, similar to autograd, enabling gradient computation for machine learning tasks.
- **Python Bindings**: Provides Python bindings for seamless integration with Python-based workflows.
- **High Performance**: Optimized for both CPU and GPU execution, ensuring maximum performance across platforms.
- **Educational Focus**: Aimed at helping users understand the underlying concepts of tensor operations, autograd, and GPU acceleration.

## Requirements

- macOS 10.15+ or iOS 13+ with Metal support
- Xcode 12+ with Command Line Tools
- Python 3.x (for Python bindings)
- CMake 3.x or higher (for building the project)

## Project Structure

```
.
â”œâ”€â”€ src
â”‚   â””â”€â”€ beta
â”‚   â”‚   â”œâ”€â”€ cpu.cpp
â”‚   â”‚   â”œâ”€â”€ cpu.h
â”‚   â”‚   â”œâ”€â”€ device.cpp
â”‚   â”‚   â”œâ”€â”€ device.h
â”‚   â”‚   â”œâ”€â”€ mps_helper.mm
â”‚   â”‚   â”œâ”€â”€ mps_helper.h
â”‚   â”‚   â””â”€â”€ tensor.mm
â”‚   â”œâ”€â”€  matrix.cpp
â”‚   â”œâ”€â”€  mps.h
â”‚   â”œâ”€â”€  mps.nm
â”‚   â”œâ”€â”€ Shaders.metal
â”‚   â”œâ”€â”€ tensor.mm
â”‚   â””â”€â”€ wrapper.cpp
â”œâ”€â”€ tests
â”‚   â”œâ”€â”€ CMakeLists.txt
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€
â”œâ”€â”€ examples
â”‚   â””â”€â”€ mlp
â”‚       â”œâ”€â”€ activations
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ main.py
â”‚       â”œâ”€â”€ costs
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ main.py
â”‚       â”œâ”€â”€ layers
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ main.py
â”‚       â”œâ”€â”€ optimizers
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ main.py
â”‚       â”œâ”€â”€ tensors
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ tensor.py
â”‚       â”œâ”€â”€ tests
â”‚       â”‚   â”œâ”€â”€ activation_methods.py
â”‚       â”‚   â”œâ”€â”€ cost_methods.py
â”‚       â”‚   â””â”€â”€ layer.py
â”‚       â””â”€â”€ tf_impl
â”‚           â”œâ”€â”€ data.json
â”‚           â”œâ”€â”€ gpt-version.py
â”‚           â”œâ”€â”€ mnist_model.h5
â”‚           â””â”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ build_ext.py
â”œâ”€â”€ CMakeLists.txt
â”œâ”€â”€ LICENSE
â”œâ”€â”€ MANIFEST.in
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ setup.py
â””â”€â”€ setup.cfg
```

## Installation

### From Source

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/metal-tensor-library.git
   cd metal-tensor-library
   ```

2. Build the C++/Objective-C++ library:
   ```bash
   mkdir build
   cd build
   cmake ..
   make
   ```

3. Install Python bindings:
   ```bash
   pip install .
   ```

### Pre-built Binaries

Coming soon...

## Usage

### C++/Objective-C++ API

```cpp
#include "MetalTensor.h"

int main() {
    MetalTensor tensor1 = MetalTensor::random({3, 3});
    MetalTensor tensor2 = MetalTensor::random({3, 3});
    
    // Define a simple computation
    MetalTensor result = tensor1 * tensor2;
    
    // Compute gradients
    result.backward();
    
    // Access the gradients
    MetalTensor grad = tensor1.grad();
    grad.print();
    return 0;
}
```

### Python API

```python
import metal_tensor as mt

# Create tensors
tensor1 = mt.random((3, 3), requires_grad=True)
tensor2 = mt.random((3, 3), requires_grad=True)

# Define a simple computation
result = tensor1 * tensor2

# Compute gradients
result.backward()

# Access the gradients
grad_tensor1 = tensor1.grad
grad_tensor2 = tensor2.grad

print("Gradient of tensor1:\n", grad_tensor1)
print("Gradient of tensor2:\n", grad_tensor2)
```

## Documentation

<!-- For detailed documentation on the API and advanced usage, refer to the [docs](docs). -->
No documentation understand it yourself ğŸ¤·ğŸ»â€â™‚ï¸


## Contributing

We welcome contributions to this project! To contribute, please fork the repository and submit a pull request with your changes. Make sure to follow the code style and add tests for new features or bug fixes.

1. Fork the repository
2. Create a new branch
3. Make your changes
4. Run tests to verify your changes
5. Submit a pull request

## License

This project is licensed under the GNU General Public License v3.0 - see the [LICENSE](LICENSE) file for details.

## Acknowledgements

- Metal framework for GPU acceleration
- Python bindings via [pybind11](https://pybind11.readthedocs.io/)
- Inspired by various tensor libraries such as NumPy and TensorFlow, and automatic differentiation systems like autograd.
